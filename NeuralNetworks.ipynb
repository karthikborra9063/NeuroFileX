{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587265a2",
   "metadata": {},
   "source": [
    "## Required Libraries (or) Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e702173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81597ff2",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a71dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = output_size\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.weights.append(np.random.uniform(size=(self.input_size,self.hidden_layers[0])))\n",
    "        self.biases.append(np.random.uniform(size=(1,self.hidden_layers[0])))\n",
    "        for i in range(1,len(hidden_layers)):\n",
    "            self.weights.append(np.random.uniform(size=(self.hidden_layers[i-1],self.hidden_layers[i])))\n",
    "            self.biases.append(np.random.uniform(size=(1,self.hidden_layers[i])))\n",
    "        self.weights.append(np.random.uniform(size=(self.hidden_layers[-1],self.output_size)))\n",
    "        self.biases.append(np.random.uniform(size=(1,self.output_size)))\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def mean_absolute_error(self, y_true, y_pred):\n",
    "        return np.mean(np.abs(y_true - y_pred))\n",
    "    \n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        true_classes = np.argmax(y_true, axis=1)\n",
    "        predicted_classes = np.argmax(y_pred, axis=1)\n",
    "        return np.mean(true_classes == predicted_classes)\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        self.activations=[X]\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            hid_input = np.dot(self.activations[i], self.weights[i]) + self.biases[i]\n",
    "            hid_output = self.sigmoid(hid_input)\n",
    "            self.activations.append(hid_output)\n",
    "        final_input= np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]\n",
    "        final_output = self.sigmoid(final_input)\n",
    "        self.activations.append(final_output)\n",
    "        return final_output\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        errors = [y - self.activations[-1]]\n",
    "        final_errors = [self.activations[-1]*(1-self.activations[-1])*errors[0]]\n",
    "        for i in range(len(self.hidden_layers), 0, -1):\n",
    "            error = final_errors[-1].dot(self.weights[i].T)\n",
    "            hid_errors = self.activations[i]*(1-self.activations[i])*error\n",
    "            errors.append(error)\n",
    "            final_errors.append(hid_errors)\n",
    "        final_errors.reverse()\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += self.activations[i].T.dot(final_errors[i]) * learning_rate\n",
    "            self.biases[i] += np.sum(final_errors[i]) * learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.feedforward(X)\n",
    "            self.backward(X, y, learning_rate)\n",
    "            \n",
    "            if epoch % 1000 == 0:\n",
    "                loss = -np.mean(np.sum(y * np.log(output + 1e-9), axis=1))\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425caa93",
   "metadata": {},
   "source": [
    "## Upload Your CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e348d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to your CSV file: iris.csv\n"
     ]
    }
   ],
   "source": [
    "    try:\n",
    "        file_path = input(\"Enter the path to your CSV file: \")\n",
    "        dataset = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c9721",
   "metadata": {},
   "source": [
    "## Seperation of Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a497ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76931ae2",
   "metadata": {},
   "source": [
    "## Data Preprocessing: Encoding and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926bf8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    label_encoders = {}\n",
    "    scaler = StandardScaler()\n",
    "    for column in X.columns:\n",
    "        if X[column].dtype == 'object': \n",
    "            le = LabelEncoder()\n",
    "            X[column] = le.fit_transform(X[column])  \n",
    "            label_encoders[column] = le  \n",
    "    X = scaler.fit_transform(X.values.astype(float))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y).reshape(-1, 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_encoded = onehot_encoder.fit_transform(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ad3c0",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6110a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450835aa",
   "metadata": {},
   "source": [
    "## Inputs for the requirements for implemenation of Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffec52f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of hidden layers: 1\n",
      "Enter the size of hidden layer 1: 3\n",
      "Enter the number of epochs: 10000\n",
      "Enter the learning rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    output_size = y_encoded.shape[1]\n",
    "    input_size = X_train.shape[1]\n",
    "    \n",
    "    num_hidden_layers = int(input(\"Enter the number of hidden layers: \"))\n",
    "    hidden_layers = []\n",
    "    for i in range(num_hidden_layers):\n",
    "        size = int(input(f\"Enter the size of hidden layer {i + 1}: \"))\n",
    "        hidden_layers.append(size)\n",
    "    \n",
    "    epochs = int(input(\"Enter the number of epochs: \"))\n",
    "    learning_rate = float(input(\"Enter the learning rate: \"))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a58b5dd",
   "metadata": {},
   "source": [
    "## Neural Network Setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66eb3acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.316967633313287\n",
      "Epoch 1000, Loss: 0.07167950643527442\n",
      "Epoch 2000, Loss: 0.06418168674769331\n",
      "Epoch 3000, Loss: 0.0620889800792365\n",
      "Epoch 4000, Loss: 0.062295416149016354\n",
      "Epoch 5000, Loss: 0.0629569196445519\n",
      "Epoch 6000, Loss: 0.06596093019981397\n",
      "Epoch 7000, Loss: 0.06692710520127519\n",
      "Epoch 8000, Loss: 0.06802828136314681\n",
      "Epoch 9000, Loss: 0.06903374148742368\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    nn = NeuralNetwork(input_size=input_size, hidden_layers=hidden_layers, output_size=output_size)\n",
    "    nn.train(X_train, y_train, epochs=epochs, learning_rate=learning_rate)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4366a",
   "metadata": {},
   "source": [
    "## Predicting Labels for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c647ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    output = nn.feedforward(X_test)\n",
    "    predictions = np.argmax(output, axis=1)\n",
    "    true_labels = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e3afc",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc83c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions after training:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 2 1 0 0]\n",
      "\n",
      "True Labels:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "Test Mean Absolute Error: 0.02499339224677966\n",
      "Test Accuracy: 97.78%\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\nPredictions after training:\")\n",
    "    print(predictions)\n",
    "    print(\"\\nTrue Labels:\")\n",
    "    print(true_labels)\n",
    "    test_predictions = nn.feedforward(X_test)\n",
    "    test_mae = nn.mean_absolute_error(y_test, test_predictions)\n",
    "    print(f\"Test Mean Absolute Error: {test_mae}\")\n",
    "    test_accuracy = nn.accuracy(y_test, test_predictions)\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a6f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac10d8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
